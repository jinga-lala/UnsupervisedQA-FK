# -*- coding: utf-8 -*-
"""spec ner

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uUu17zxpaC4RwTqn7mRQJGB_tHKJNkDW
"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/SQL query files-mobile/specs with attributes.csv')
df.head()

df = df.loc[df['name']=='mobile']

df.head()

spec_list = df['attributedisplayname'].tolist()
spec_allowed_values = df['allowedvalues'].tolist()
# print(spec_list[:20])
# print(spec_allowed_values[:20])

import math, re
def remove_nan(spec_allowed_values):
  buf = []
  for i in spec_allowed_values:
    try:
      if math.isnan(i):
        pass
    except:
      buf.append(i)

  buf = list(set(buf))
  # print(len(buf), buf[:10])
  spec_allowed_values = buf.copy()
  return spec_allowed_values
spec_allowed_values = remove_nan(spec_allowed_values)

def split_at_bars(spec_allowed_values):
  buf = []
  for i in spec_allowed_values:
    i = i.strip().split('||')
    # print(i)
    buf.extend(i)
  buf = list(set(buf))
  spec_allowed_values = buf.copy()
  # print(buf)
  return spec_allowed_values
spec_allowed_values =split_at_bars(spec_allowed_values)

"""Rule to add: A number is always taken with its next token as entity."""

def parse_spec_list(spec_list):
  buf = []
  spec_list = list(set(spec_list))
  for i in spec_list:
    try:
      i = re.sub('_', ' ', i)
      # print(i)
      buf.append(i)
    except:
      # print(i)
      pass
  buf = list(set(buf))
  spec_list = buf.copy()
  # print(buf[:20])
  return spec_list
spec_list = parse_spec_list(spec_list)

spec_list.extend(spec_allowed_values)

df2 = df.loc[df.attributetype=="NUMBER"]
df3 = df.loc[df.attributetype=="DECIMAL"]
df2.head()

buf = df2['attributedisplayname'].tolist()
# buf2 = df2['allowedvalues'].tolist() #in mobile it is useless
buf2 = df2['qualifierallowedvalues'].tolist()
buf = parse_spec_list(buf)
buf2 = remove_nan(buf2)
buf2 = split_at_bars(buf2)
buf.extend(buf2)
spec_with_num = buf.copy()

buf = df3['attributedisplayname'].tolist()
# buf2 = df2['allowedvalues'].tolist() #in mobile it is useless
buf2 = df3['qualifierallowedvalues'].tolist()
buf = parse_spec_list(buf)

buf2 = remove_nan(buf2)
buf2 = split_at_bars(buf2)
buf.extend(buf2)
spec_with_num.extend(buf)

qa = pd.read_csv('/content/drive/My Drive/SQL query files-mobile/Q&A.csv')
qa.head()

question = qa.question.tolist()
answer = qa.answer.tolist()
combined = [(i,j) for (i,j) in zip(question, answer)]
# print(len(combined))
combined = list(set(combined))
# print(len(combined))
long_combined = []
for i,j in combined:
  try:
    if len(j) > 20 :
      long_combined.append((i,j))
  except:
      pass
    # print(i)
# print(len(long_combined))
# print(long_combined[:10])
long_combined = [(x.strip(), y.strip()) for x,y in long_combined]
long_combined = [(re.sub('\n',' ',y),re.sub('\n',' ',x)) for y,x in long_combined]
long_combined = [(x.encode('ascii', 'ignore').decode('ascii'), y.encode('ascii', 'ignore').decode('ascii')) for x,y in long_combined] #remove emojis
# print(long_combined[0:5])

'''
import difflib
f = open("sequence_matching.txt","w")
used=0
wasted=0
for j,(q,ans) in enumerate(long_combined):
  if j==1000:
    break
  a = difflib.get_close_matches(ans, spec_allowed_values, 1, 0.5)
  if len(a)!=0:
    used = used +1
    seq =  difflib.SequenceMatcher(None, ans , a).get_matching_blocks()[0]
    print(a, ans, seq)
    f.write(a[0]+", "+ans+", "+q+"\n")
  else:
    wasted = wasted+1
f.close()

print(used, wasted)
'''
# !pip install fasttext

import fasttext
model = fasttext.load_model('/content/drive/My Drive/SQL query files-mobile/vectors.model')

# !pip install -U spacy

# !python -m spacy download en

import spacy
sp = spacy.load('en_core_web_sm')

all_stopwords = sp.Defaults.stop_words

all_stopwords.add(',')
all_stopwords.remove('not')
all_stopwords.remove('no')
'no' in all_stopwords

',' in all_stopwords

import numpy as np
# f= open("wordvector.csv","w")
spec_emb = np.zeros([len(spec_list), 100])
# f.write("Spec , answer , question \n" )
for i in range(len(spec_list)):
  # spec_emb[i,:] = model[spec_list[i]]/ np.linalg.norm(model[spec_list[i]])
  a = spec_list[i].split()
  emb = np.zeros([1,100])
  length = 0
  for j in a:
    if j not in all_stopwords:
      j = j.lower()
      length +=1
      emb[0:] += model[j]
  # emb[0:] = emb[0:]/len(a)
  emb[0:] = emb[0:]/length
  spec_emb[i,:] = emb/ np.linalg.norm(emb)
top3_specs_combined = []
entity_combined = []
# for j,(q,ans) in enumerate(long_combined):
#   if j==5:
#     break
def get_answertext_wordvector(ans):
  # ans_emb = model[ans].reshape(-1,1)
  ans_emb = np.zeros([1,100])
  split_ans = ans.split()
  pred_entity = []
  buf = np.zeros([1,100])
  length = 0
  for j in split_ans:
    if j not in all_stopwords:
      length +=1 
      j = j.lower()
      ans_emb[0:] += model[j]
      buf = buf + model[j]
      pred_entity.append(spec_list[np.argmax(spec_emb@(buf.reshape(-1,1)))])
      buf = model[j]
    else:
      pred_entity.append(None)
  
  ans_emb[0:] = ans_emb[0:]/ length
  ans_emb = ans_emb.reshape(-1,1)
  # print(ans,":", spec_list[np.argmax(spec_emb@ans_emb)], np.max(spec_emb@ans_emb))
  top3_specs =  np.argsort(spec_emb@ans_emb, axis=0)[-3:][::-1].flatten()
  top3_specs = [spec_list[i] for i in top3_specs]

  entities = []
  entities_type = []
  for j in top3_specs:

    if j not in pred_entity:
      continue
    
    buf = [i for i,x in enumerate(pred_entity) if x==j] 
    # print(j,buf)
    prev = -1
    e = ""
    for k in buf:
      if k==prev+1:
        e += " "+split_ans[k]
      else:
        if e!="":
          if len(df.attributetype[df.attributename==j].tolist()) !=0:
            entities_type.append(df.attributetype[df.attributename==j].tolist()[0])
          else:
            entities_type.append("NOUN") #DEFAULT TYPE
          entities.append(e)
        e = split_ans[k]
      prev = k

    if e != "":
      if len(df.attributetype[df.attributename==j].tolist()) !=0:
        entities_type.append(df.attributetype[df.attributename==j].tolist()[0])
      else:
        entities_type.append("NOUN") #DEFAULT TYPE
      entities.append(e)

  entities_start = [ans.find(e) for e in entities ]

  return [(a,b,c) for a,b,c in zip(entities, entities_start, entities_type)]
  # print(ans, entities)

  # f.write(spec_list[np.argmax(spec_emb@ans_emb)]+" ; "+' '.join(ans)+" ; "+q+"\n")

"""Right now taking all top3 in consideration for the entity selection
Can tweak on the length of the entities list to limit on selecting the first top spec entity!
"""
  # print( pred_entity, top3_specs)

"""Using word mover distance as a metric"""

